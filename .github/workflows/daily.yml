name: Daily Job Search

permissions:
  contents: write

on:
  schedule:
    - cron: "0 4 * * *"
  workflow_dispatch:

jobs:
  run-job-search:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi

      - name: Run job crawler
        run: python run.py

      - name: Collect JSON outputs
        run: |
          mkdir -p results
          find . -maxdepth 2 -type f -name "job_results_*.json" -exec mv {} results/ \;

      - name: Build dashboards
        run: |
          for f in results/job_results_*.json; do
            echo "➡️ Build dashboard for $f"
            python build_jobs_dashboard.py --in-json "$f"
          done

      - name: Cleanup oldest JSON (keep 30 latest)
        run: |
          ls -t results/job_results_*.json | tail -n +31 | xargs -r rm

      - name: Cleanup oldest HTML (keep 30 latest)
        run: |
          ls -t results/job_results_*.html | tail -n +31 | xargs -r rm

      - name: Debug results
        run: |
          echo "--- JSON ---"
          ls -l results | grep .json || true
          echo "--- HTML ---"
          ls -l results | grep .html || true
      - name: Commit results to data-history
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Daily job results"
          file_pattern: |
            results/*.json
            results/*.html
          branch: data-history
          create_branch: true
          push_options: '--force-with-lease'
