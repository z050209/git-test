name: Daily Job Search

permissions:
  contents: write

on:
  schedule:
    - cron: "0 4 * * *"    # æ¯å¤© UTC 4:00 = æ–°åŠ å¡ä¸­åˆ 12:00
  workflow_dispatch:        # æ‰‹åŠ¨è§¦å‘

jobs:
  run-job-search:
    runs-on: ubuntu-latest

    steps:
      # 1. Checkout mainï¼ˆåªç”¨æ¥æ‹¿ä»£ç ï¼‰
      - name: Checkout main branch
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: main

      # 2. Reset æœ¬åœ°åˆ°è¿œç«¯ mainï¼Œä¿è¯ä»£ç å¹²å‡€
      - name: Reset local to remote main
        run: |
          git fetch origin main
          git reset --hard origin/main
          git clean -fd

      # 3. Setup Python
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # 4. Install deps
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      # 5. Run crawler
      - name: Run job crawler
        run: python run.py

      # 6. Collect results
      - name: Collect results
        run: |
          mkdir -p results
          find . -maxdepth 2 -type f -name "job_results_*.json" -exec mv {} results/ \;

      # 7. Generate dashboards
      - name: Generate dashboards
        run: |
          for f in results/job_results_*.json; do
            echo "â¡ï¸ Building html for $f"
            python build_jobs_dashboard.py --in-json "$f"
          done

      # 8. Remove old files (>30 days)
      - name: Cleanup > 30 days
        run: |
          find results -type f -name "job_results_*.json" -mtime +30 -print -delete || true
          find results -type f -name "job_results_*.html" -mtime +30 -print -delete || true

      # 9. Keep only newest 30
      - name: Cleanup newest 30
        run: |
          ls -t results/job_results_*.json | tail -n +31 | xargs -r rm
          ls -t results/job_results_*.html | tail -n +31 | xargs -r rm

      # ğŸ”Ÿ Commit & push åˆ° data-history åˆ†æ”¯ï¼ˆä¸å†åŠ¨ mainï¼‰
      - name: Commit and push to data-history
        run: |
          # é…ç½® git ç”¨æˆ·
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # æŠŠè¿œç«¯ data-history æ‹‰ä¸‹æ¥ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
          git fetch origin data-history || true
          if git branch -r | grep -q "origin/data-history"; then
            # å¦‚æœè¿œç«¯å·²æœ‰ data-historyï¼Œç”¨å®ƒä½œä¸ºèµ·ç‚¹
            git checkout -B data-history origin/data-history
          else
            # å¦åˆ™ä»å½“å‰ main å»ºä¸€ä¸ªæ–°çš„ data-history
            git checkout -B data-history
          fi

          # ç¡®ä¿ results ç›®å½•åœ¨å½“å‰å·¥ä½œåŒº
          ls -R
          echo "Staging results/"
          git add results || true

          # æ²¡å˜åŒ–å°±ä¸ commit
          if git diff --cached --quiet; then
            echo "No changes to commit."
          else
            git commit -m "Daily job scraping + dashboards"
            # æ¨é€åˆ°è¿œç«¯ data-historyï¼Œé¿å…å†å²å†²çªç”¨ --force-with-lease
            git push origin data-history --force-with-lease
          fi
