<!DOCTYPE html><html><head><meta charset='utf-8'><title>Stanford AI Research</title>
    <style>
    body { font-family: 'Inter', 'Helvetica', sans-serif; margin: 0; padding: 2rem; background:#f5f7fb; }
    h1 { margin-bottom: 1rem; }
    a { color: #1455cc; text-decoration: none; }
    .lab-card { background: #fff; padding: 1.5rem; margin-bottom: 1rem; border-radius: 12px; box-shadow: 0 6px 14px rgba(0,0,0,0.05); }
    .topics { color: #4a5568; margin-top: 0; }
    .people-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(260px, 1fr)); gap: 1rem; }
    .person-card { border: 1px solid #e2e8f0; border-radius: 10px; padding: 0.75rem; background:#fafbff; }
    .person-card h4 { margin: 0 0 0.25rem 0; }
    .role { color: #6b7280; margin: 0 0 0.5rem 0; }
    .papers { padding-left: 1rem; margin: 0; }
    .papers li { margin-bottom: 0.75rem; }
    .paper-overview { margin: 0.25rem 0; color:#374151; font-size: 0.95rem; }
    .paper-figure img { max-width: 100%; border-radius: 8px; margin-top: 0.35rem; }
    </style>
    </head><body><h1>Stanford AI Research</h1><section class='lab-card'><h2><a href='https://ai.stanford.edu/people/' target='_blank'>Stanford AI Lab (SAIL)</a></h2><p class='topics'>Topics: robotics, computer vision, nlp, multimodal</p><div class='people-grid'></div></section><section class='lab-card'><h2><a href='https://hai.stanford.edu/people/faculty' target='_blank'>HAI Faculty</a></h2><p class='topics'>Topics: llm, multimodal, policy</p><div class='people-grid'></div></section><section class='lab-card'><h2><a href='https://nlp.stanford.edu/people/' target='_blank'>Stanford NLP Group</a></h2><p class='topics'>Topics: nlp, llm, rlhf</p><div class='people-grid'><div class='person-card'><h4><a href='https://nlp.stanford.edu/people/' target='_blank'>people</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://nlp.stanford.edu/people/' target='_blank'>Linguistics & Computer Science</a><p class='paper-overview'>Linguistics & Computer Science</p></li><li><a href='https://nlp.stanford.edu/people/' target='_blank'>Linguistics & Computer Science</a><p class='paper-overview'>Linguistics & Computer Science</p></li><li><a href='https://nlp.stanford.edu/people/' target='_blank'>Computer Science & HAI</a><p class='paper-overview'>Computer Science & HAI</p></li></ul></div><div class='person-card'><h4><a href='https://nlp.stanford.edu/pubs/' target='_blank'>publications</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='http://nlp.stanford.edu/~manning/' target='_blank'>Christopher D. Manning</a><p class='paper-overview'>Christopher D. Manning , Prabhakar Raghavan , and Hinrich Sch√ºtze .</p></li><li><a href='http://nlp.stanford.edu/~manning/' target='_blank'>Christopher D. Manning</a><p class='paper-overview'>Christopher D. Manning and Hinrich Sch√ºtze .</p></li><li><a href='http://spot.colorado.edu/~bfox/' target='_blank'>Barbara A. Fox</a><p class='paper-overview'>Barbara A. Fox , Dan Jurafsky , and Laura A.</p></li></ul></div><div class='person-card'><h4><a href='https://ai.stanford.edu/blog/nlp/' target='_blank'>research blog</a></h4><p class='role'>Researcher</p><ul class='papers'><li><a href='https://rosewang2008.github.io/' target='_blank'>Rose E. Wang</a><p class='paper-overview'>Rose E. Wang and Megha Srivastava</p></li><li><a href='https://cs.stanford.edu/~dorarad/' target='_blank'>Drew A. Hudson</a><p class='paper-overview'>Compiled by Drew A. Hudson</p></li><li><a href='https://cs.stanford.edu/~eix/' target='_blank'>Sang Michael Xie</a><p class='paper-overview'>Sang Michael Xie and Sewon Min</p></li></ul></div><div class='person-card'><h4><a href='https://nlp.stanford.edu/software/' target='_blank'>software</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://nlp.stanford.edu/software/' target='_blank'>The Stanford NLP Group makes some of our
    Natural Language Processing software
    available to everyone!  We provide statistical NLP,
    deep learning NLP, and rule-based NLP tools for
    major computational linguistics problems, which can be
    incorporated into applications with human language technology needs.
    These packages are widely used in industry, academia, and government.</a><p class='paper-overview'>The Stanford NLP Group makes some of our Natural Language Processing software available to everyone! We provide statistical NLP, deep learning NLP, and rule-based NLP tools for major computational linguistics problems, which can be incorporated into applications with human language technology needs.</p></li><li><a href='https://nlp.stanford.edu/software/' target='_blank'>This code is actively being developed, and we try to answer questions and
	fix bugs on a best-effort basis.</a><p class='paper-overview'>This code is actively being developed, and we try to answer questions and fix bugs on a best-effort basis.</p></li><li><a href='http://www.gnu.org/licenses/gpl-2.0.html' target='_blank'>GNU
        General Public License</a><p class='paper-overview'>These software distributions are open source, licensed under the GNU General Public License (v3 or later for Stanford CoreNLP; v2 or later for the other releases). Note that this is the full GPL, which allows many free uses, but does not allow its incorporation (even in part or in translation) into any type of proprietary software which you distribute.</p></li></ul></div><div class='person-card'><h4><a href='https://nlp.stanford.edu/teaching/' target='_blank'>teaching</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://nlp.stanford.edu/teaching/' target='_blank'>A key mission of the Natural Language Processing Group is
          graduate and undergraduate education in all areas of Human
          Language Technology including its applications, history, and social context.</a><p class='paper-overview'>A key mission of the Natural Language Processing Group is graduate and undergraduate education in all areas of Human Language Technology including its applications, history, and social context.</p></li><li><a href='https://nlp.stanford.edu/prospective/' target='_blank'>information for prospective
            graduate students</a><p class='paper-overview'>Here is some basic information for prospective graduate students .</p></li><li><a href='https://nlp.stanford.edu/teaching/' target='_blank'>Stanford University offers a rich assortment of courses in
          Natural Language Processing and related areas, including 
          foundational courses as well as advanced seminars.</a><p class='paper-overview'>Stanford University offers a rich assortment of courses in Natural Language Processing and related areas, including foundational courses as well as advanced seminars.</p></li></ul></div><div class='person-card'><h4><a href='https://nlp.stanford.edu/prospective/' target='_blank'>join</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://nlp.stanford.edu/prospective/' target='_blank'>The Stanford NLP Group is always on the lookout for budding new
      computational linguists.  Stanford has a great program at the
      cutting edge of modern computational linguistics.</a><p class='paper-overview'>The Stanford NLP Group is always on the lookout for budding new computational linguists. Stanford has a great program at the cutting edge of modern computational linguistics.</p></li><li><a href='https://nlp.stanford.edu/prospective/' target='_blank'>If you have questions about admissions, please check the
      graduate admissions web pages listed on the right, or write to
      the admissions email addresses listed.  We NLP Group members
      attempt to answer specific NLP-related admissions questions
      (although sometimes we get too busy...), but in general it isn't
      necessary or helpful to contact us to let us know that you want to
      apply or have applied for admission.</a><p class='paper-overview'>If you have questions about admissions, please check the graduate admissions web pages listed on the right, or write to the admissions email addresses listed. We NLP Group members attempt to answer specific NLP-related admissions questions (although sometimes we get too busy...), but in general it isn't necessary or helpful to contact us to let us know that you want to apply or have applied for admission.</p></li><li><a href='https://linguistics.stanford.edu/degree-programs/graduate-admissions' target='_blank'>Linguistics Graduate Admissions</a><p class='paper-overview'>Web: Linguistics Graduate Admissions Email: linguistics@stanford.edu</p></li></ul></div><div class='person-card'><h4><a href='https://nlp.stanford.edu/new_local/' target='_blank'>local</a></h4><p class='role'>Member</p><ul class='papers'></ul></div><div class='person-card'><h4><a href='http://nlp.stanford.edu/~manning/' target='_blank'>Chris Manning</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='http://nlp.stanford.edu/~manning/papers/Magesh-Hallucination‚ÄêFree-2025.pdf' target='_blank'>Our paper on hallucinating legal LLMs</a><p class='paper-overview'>Our paper on hallucinating legal LLMs is out in Journal of Empirical Legal Studies (2025).</p></li><li><a href='https://www.amacad.org/new-members-2025' target='_blank'>elected to the American Academy of Arts and Sciences</a><p class='paper-overview'>I was elected to the American Academy of Arts and Sciences (2025).</p></li><li><a href='https://www.nae.edu/331605/NAENewClass2025' target='_blank'>elected to the National Academy of Engineering</a><p class='paper-overview'>I was elected to the National Academy of Engineering (NAE) for the development and dissemination of natural language processing methods (2025).</p></li></ul></div><div class='person-card'><h4><a href='http://web.stanford.edu/~jurafsky/' target='_blank'>Dan Jurafsky</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://arxiv.org/pdf/2506.11035' target='_blank'>Tversky Neural Networks: Psychologically Plausible Deep Learning with Differentiable Tversky Similarity.</a><p class='paper-overview'>Doumbouya, Moussa Koulako Bala, Dan Jurafsky, and Christopher D. Manning.</p></li><li><a href='https://arxiv.org/pdf/2509.21556' target='_blank'>AI for Sustainable Future Foods.</a><p class='paper-overview'>Bianca Datta, Markus J. Buehler, Yvonne Chow, Kristina Gligoric, Dan Jurafsky, David L.</p></li><li><a href='https://arxiv.org/pdf/2505.13995' target='_blank'>ELEPHANT: Measuring and Understanding Social Sycophancy in LLMs.</a><p class='paper-overview'>Myra Cheng*, Sunny Yu*, Cinoo Lee, Pranav Khadpe, Lujain Ibrahim, Dan Jurafsky. ELEPHANT: Measuring and Understanding Social Sycophancy in LLMs.</p></li></ul></div><div class='person-card'><h4><a href='http://cs.stanford.edu/~pliang/' target='_blank'>Percy Liang</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='http://cs.stanford.edu/~pliang/' target='_blank'>I am drawn to simple things, want to understand things deeply, and like to build useful systems.
  I am interested in:</a><p class='paper-overview'>I am drawn to simple things, want to understand things deeply, and like to build useful systems. I am interested in:</p></li><li><a href='https://arxiv.org/pdf/2305.10429' target='_blank'>weight multiple datasets</a><p class='paper-overview'>How do we build foundation models from first principles? How do we weight multiple datasets ?</p></li><li><a href='http://cs.stanford.edu/~pliang/software' target='_blank'>code for older projects</a><p class='paper-overview'>Here is some code for older projects .</p></li></ul></div><div class='person-card'><h4><a href='http://web.stanford.edu/~cgpotts/' target='_blank'>Chris Potts</a></h4><p class='role'>Member</p><ul class='papers'></ul></div><div class='person-card'><h4><a href='https://thashim.github.io' target='_blank'>Tatsunori Hashimoto</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://thashim.github.io' target='_blank'>Assistant Professor, Stanford</a><p class='paper-overview'>Assistant Professor, Stanford</p></li><li><a href='https://thashim.github.io' target='_blank'>thashim [AT] stanford.edu</a><p class='paper-overview'>thashim [AT] stanford.edu</p></li><li><a href='https://thashim.github.io' target='_blank'>I am currently an assistant professor at the computer science department in Stanford university.</a><p class='paper-overview'>I am currently an assistant professor at the computer science department in Stanford university.</p></li></ul></div><div class='person-card'><h4><a href='https://suif.stanford.edu/~lam/' target='_blank'>Monica Lam</a></h4><p class='role'>Member</p><ul class='papers'></ul></div><div class='person-card'><h4><a href='https://cs.stanford.edu/~diyiy/' target='_blank'>Diyi Yang</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://cs.stanford.edu/' target='_blank'>Computer Science Department</a><p class='paper-overview'>Computer Science Department</p></li><li><a href='https://nlp.stanford.edu/' target='_blank'>Natural Language Processing Group</a><p class='paper-overview'>Natural Language Processing Group</p></li><li><a href='https://www.cs.stanford.edu/' target='_blank'>Computer Science Department</a><p class='paper-overview'>I am an assistant professor in the Computer Science Department at Stanford , affiliated with the Stanford NLP Group , Stanford HCI Group , Stanford AI Lab (SAIL) , and Stanford Human-Centered Artificial Intelligence (HAI) . I am interested in Socially Aware NLP , Large Language Models (LLMs) and Human-AI Interaction , with a focus on how LLMs can augment human capabilities across research, work and well-being.</p></li></ul></div><div class='person-card'><h4><a href='https://homes.cs.washington.edu/~yejin/' target='_blank'>Yejin Choi</a></h4><p class='role'>Member</p><ul class='papers'></ul></div><div class='person-card'><h4><a href='https://cocolab.stanford.edu/ndg.html' target='_blank'>Noah Goodman</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://scholar.google.com/citations?user=OUpIbcQAAAAJ' target='_blank'>Scholar metrics and bibliography</a><p class='paper-overview'>Scholar metrics and bibliography</p></li><li><a href='https://cocolab.stanford.edu/ndg.html' target='_blank'>Email: ngoodman at stanford dot edu</a><p class='paper-overview'>Email: ngoodman at stanford dot edu</p></li><li><a href='https://cocolab.stanford.edu/ndg.html' target='_blank'>Office: 356 Jordan Hall, Stanford.</a><p class='paper-overview'>Office: 356 Jordan Hall, Stanford.</p></li></ul></div><div class='person-card'><h4><a href='https://douwekiela.github.io' target='_blank'>Douwe Kiela</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://douwekiela.github.io' target='_blank'>My work focuses on machine learning and natural language processing. My research interests lie in developing better models for (grounded, multi-agent, retrieval-augmented) language understanding and better tools for evaluation and benchmarking.</a><p class='paper-overview'>My work focuses on machine learning and natural language processing. My research interests lie in developing better models for (grounded, multi-agent, retrieval-augmented) language understanding and better tools for evaluation and benchmarking.</p></li></ul></div><div class='person-card'><h4><a href='https://www.dorademszky.com' target='_blank'>Dora Demszky</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://hai.stanford.edu/news/how-math-teachers-are-making-decisions-about-using-ai' target='_blank'>How Do Math Teachers Make Decisions About Using AI?</a><p class='paper-overview'>How Do Math Teachers Make Decisions About Using AI? : read our brief report from the 60-teacher summit we organized in June.</p></li><li><a href='https://github.com/ddemszky/classroom-transcript-analysis' target='_blank'>NCTE classroom transcript dataset</a><p class='paper-overview'>Our NCTE classroom transcript dataset received the best IEDMS Publicly Available Educational Dataset Prize ! üèÜ</p></li><li><a href='https://edunlp.stanford.edu/news/practitioner-voices-summit-shaping-future-ai-math-education' target='_blank'>Practitioner Voices Summit</a><p class='paper-overview'>Our Practitioner Voices Summit in June hosted 60 teachers from 22 states, to provide them with a platform to inform R&D related to AI in classrooms. The rooms were buzzing with energy with all the ideas, and the dedication of these teachers to their students.</p></li></ul></div><div class='person-card'><h4><a href='https://ai.stanford.edu/~tengyuma/' target='_blank'>Tengyu Ma</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://ai.stanford.edu/~tengyuma/' target='_blank'>The first name is pronounced as Tung-√º, where √º is roughly a mixture of i and u, as in German. I'm more than happy to accept any approximation, so please feel free to use your favorite variants/surrogates!</a><p class='paper-overview'>The first name is pronounced as Tung-√º, where √º is roughly a mixture of i and u, as in German. I'm more than happy to accept any approximation, so please feel free to use your favorite variants/surrogates!</p></li><li><a href='https://ai.stanford.edu/~tengyuma/' target='_blank'>Hi! I am an assistant professor of computer science at Stanford. My research interests broadly include topics in machine learning, algorithms and their theory, such as deep learning, (deep) reinforcement learning, pre-training / foundation models, robustness, non-convex optimization, distributed optimization, and high-dimensional statistics.</a><p class='paper-overview'>Hi! I am an assistant professor of computer science at Stanford.</p></li><li><a href='https://cs.stanford.edu/~eix/' target='_blank'>Sang Michael Xie</a><p class='paper-overview'>Sang Michael Xie (Ph.D. 2024, co-advised with Percy Liang, research scientist at Meta GenAI)</p></li></ul></div><div class='person-card'><h4><a href='http://www.azaliamirhoseini.com' target='_blank'>Azalia Mirhoseini</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://cs229s.stanford.edu/fall2024/' target='_blank'>Systems for Machine Learning</a><p class='paper-overview'>Fall 2023, Fall 2024 - CS229s: Systems for Machine Learning</p></li><li><a href='https://cs329a.stanford.edu/' target='_blank'>Self-Improving AI Agent</a><p class='paper-overview'>Winter 2024, Fall 2025 - CS329a: Self-Improving AI Agent</p></li><li><a href='http://www.azaliamirhoseini.com' target='_blank'>Distinguished Speaker Series, IBM√¢¬Ä¬ôs Watson Research Center, 2025</a><p class='paper-overview'>Distinguished Speaker Series, IBM√¢¬Ä¬ôs Watson Research Center, 2025</p></li></ul></div></div></section><section class='lab-card'><h2><a href='https://crfm.stanford.edu/people.html' target='_blank'>Center for Research on Foundation Models (CRFM)</a></h2><p class='topics'>Topics: foundation model, preference learning, tokenization</p><div class='people-grid'><div class='person-card'><h4><a href='https://crfm.stanford.edu/people.html' target='_blank'>People</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='http://www.joonsungpark.com/' target='_blank'>Joon Sung Park</a><p class='paper-overview'>¬© 2024. Stanford Center for Research on Foundation Models.</p></li></ul></div><div class='person-card'><h4><a href='https://crfm.stanford.edu/report.html' target='_blank'>Report</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='http://www.joonsungpark.com/' target='_blank'>Joon Sung Park</a><p class='paper-overview'>¬© 2024. Stanford Center for Research on Foundation Models.</p></li></ul></div><div class='person-card'><h4><a href='https://crfm.stanford.edu/helm' target='_blank'>HELM</a></h4><p class='role'>Member</p><ul class='papers'></ul></div><div class='person-card'><h4><a href='https://crfm.stanford.edu/2023/06/16/levanter-1_0-release.html' target='_blank'>Levanter</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://crfm.stanford.edu/2023/06/16/levanter-1_0-release.html' target='_blank'>Legible: Levanter comes with a new named tensor library named Haliax that makes it easy to write legible, composable deep learning code, while still being high performance.</a><p class='paper-overview'>Legible : Levanter comes with a new named tensor library named Haliax that makes it easy to write legible, composable deep learning code, while still being high performance.</p></li><li><a href='https://crfm.stanford.edu/2023/06/16/levanter-1_0-release.html' target='_blank'>Scalable: Levanter is designed to scale to large models, and to be able to train on a variety of hardware, including GPUs and TPUs.</a><p class='paper-overview'>Scalable : Levanter is designed to scale to large models, and to be able to train on a variety of hardware, including GPUs and TPUs.</p></li><li><a href='https://crfm.stanford.edu/2023/06/16/levanter-1_0-release.html' target='_blank'>Reproducible: Levanter is bitwise deterministic, meaning that the same configuration will always produce the same results, even in the face of preemption and resumption.</a><p class='paper-overview'>Reproducible : Levanter is bitwise deterministic, meaning that the same configuration will always produce the same results, even in the face of preemption and resumption.</p></li></ul></div><div class='person-card'><h4><a href='https://crfm.stanford.edu/fmti' target='_blank'>FMTI</a></h4><p class='role'>Member</p><ul class='papers'></ul></div><div class='person-card'><h4><a href='https://crfm.stanford.edu/open-fms/' target='_blank'>Openness</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://crfm.stanford.edu/open-fms/' target='_blank'>Analyzing the benefits and risks of foundation models with widely available weights</a><p class='paper-overview'>Analyzing the benefits and risks of foundation models with widely available weights</p></li><li><a href='https://arxiv.org/pdf/2403.07918v1.pdf' target='_blank'>Paper (ICML 2024 Oral)</a><p class='paper-overview'>Paper (ICML 2024 Oral) Blog Policy brief Authors</p></li><li><a href='https://crfm.stanford.edu/open-fms/' target='_blank'>Identifying distinctive properties.Foundation models released with widely available
                        weights have
                        distinctive properties that lead to both their benefits and risks. We outline five
                        properties
                        that inform our analysis of their societal impact: broader access, greater customizability, the
                        ability for local inference and adaptability, an inability to rescind model weights once
                        released, and an inability to monitor or moderate usage.</a><p class='paper-overview'>Identifying distinctive properties. Foundation models released with widely available weights have distinctive properties that lead to both their benefits and risks.</p></li></ul></div><div class='person-card'><h4><a href='https://crfm.stanford.edu/ecosystem-graphs/' target='_blank'>Ecosystem Graphs</a></h4><p class='role'>Member</p><ul class='papers'></ul></div><div class='person-card'><h4><a href='https://crfm.stanford.edu/policy.html' target='_blank'>Policy</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='http://www.joonsungpark.com/' target='_blank'>Joon Sung Park</a><p class='paper-overview'>¬© 2024. Stanford Center for Research on Foundation Models.</p></li></ul></div><div class='person-card'><h4><a href='https://crfm.stanford.edu/blog.html' target='_blank'>Blog</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='http://www.joonsungpark.com/' target='_blank'>Joon Sung Park</a><p class='paper-overview'>¬© 2024. Stanford Center for Research on Foundation Models.</p></li></ul></div><div class='person-card'><h4><a href='https://cs.stanford.edu/~pliang/' target='_blank'>Percy Liang</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://cs.stanford.edu/~pliang/' target='_blank'>I am drawn to simple things, want to understand things deeply, and like to build useful systems.
  I am interested in:</a><p class='paper-overview'>I am drawn to simple things, want to understand things deeply, and like to build useful systems. I am interested in:</p></li><li><a href='https://arxiv.org/pdf/2305.10429' target='_blank'>weight multiple datasets</a><p class='paper-overview'>How do we build foundation models from first principles? How do we weight multiple datasets ?</p></li><li><a href='https://cs.stanford.edu/~pliang/software' target='_blank'>code for older projects</a><p class='paper-overview'>Here is some code for older projects .</p></li></ul></div><div class='person-card'><h4><a href='https://med.stanford.edu/mimi.html' target='_blank'>Akshay Chaudhari</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://med.stanford.edu/mimi.html' target='_blank'>Find a doctor</a><p class='paper-overview'>Find a doctor</p></li><li><a href='http://www.stanfordchildrens.org/en/search/default?tab=doctors' target='_blank'>Pediatrician or pediatric specialist</a><p class='paper-overview'>Pediatrician or pediatric specialist</p></li><li><a href='https://med.stanford.edu/mimi.html' target='_blank'>Clinics & Services</a><p class='paper-overview'>Clinics & Services</p></li></ul></div><div class='person-card'><h4><a href='https://guestrin.stanford.edu' target='_blank'>Carlos Guestrin</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://guestrin.stanford.edu' target='_blank'>Computer Science, Stanford University</a><p class='paper-overview'>Computer Science, Stanford University</p></li><li><a href='https://ai.stanford.edu' target='_blank'>Stanford AI Lab</a><p class='paper-overview'>Director, Stanford AI Lab (SAIL) Fortinet Founders Professor Senior Fellow, Institute for Human-Centered AI Chief Scientist, Visual Layer Chief Scientist, Virtue AI Member of the National Academy of Engineering</p></li><li><a href='https://ai.stanford.edu' target='_blank'>Stanford AI Lab (SAIL)</a><p class='paper-overview'>Carlos Guestrin Fortinet Founders Professor, Computer Science, Stanford Director, Stanford AI Lab (SAIL) Senior Fellow, Stanford Institute for Human-Centered AI (HAI) Chief Scientist, Visual Layer Chief Scientist, Virtue AI Member of the National Academy of Engineering Research Focus Machine Learning Methods Explainability, Fairness & Ethics of AI Machine Learning Systems</p></li></ul></div><div class='person-card'><h4><a href='https://ai.stanford.edu/~cbfinn/' target='_blank'>Chelsea Finn</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://ai.stanford.edu/~cbfinn/' target='_blank'>Chelsea Finncbfinn at cs dot stanford dot edu</a><p class='paper-overview'>Chelsea Finn cbfinn at cs dot stanford dot edu</p></li><li><a href='https://ai.stanford.edu/~cbfinn/' target='_blank'>I am interested in the capability of robots and other agents to develop broadly intelligent behavior through learning and interaction.</a><p class='paper-overview'>I am interested in the capability of robots and other agents to develop broadly intelligent behavior through learning and interaction.</p></li><li><a href='https://www.nytimes.com/2021/07/20/technology/ai-education-neural-networks.html' target='_blank'>featured in the New York Times</a><p class='paper-overview'>Our work on meta-learning for giving feedback to students was featured in the New York Times . See the blog post , paper , and slides for more information.</p></li></ul></div><div class='person-card'><h4><a href='https://cs.stanford.edu/~chrismre/' target='_blank'>Chris Re</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://cs.stanford.edu/~chrismre/#courses' target='_blank'>Teaching and Awards</a><p class='paper-overview'>Teaching and Awards</p></li><li><a href='https://cs.stanford.edu/~chrismre/' target='_blank'>On the AI side, I am fascinated by how we can learn from increasingly weak forms of supervision, the basis of new architectures, the role of data, and by the mathematical foundations of such techniques.</a><p class='paper-overview'>On the AI side, I am fascinated by how we can learn from increasingly weak forms of supervision, the basis of new architectures, the role of data, and by the mathematical foundations of such techniques.</p></li><li><a href='https://hazyresearch.stanford.edu/blog/2025-11-18-intelligence-per-watt' target='_blank'>Intelligence per Watt</a><p class='paper-overview'>Intelligence per Watt ( paper | repo ) measuring efficiency of AI and foundation models!</p></li></ul></div><div class='person-card'><h4><a href='https://nlp.stanford.edu/manning/' target='_blank'>Christopher Manning</a></h4><p class='role'>Member</p><ul class='papers'></ul></div><div class='person-card'><h4><a href='https://crypto.stanford.edu/~dabo/' target='_blank'>Dan Boneh</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://crypto.stanford.edu/~dabo/' target='_blank'>Mail: Computer Science Dept., 389 Jane Stanford Way, Stanford, CA 94305</a><p class='paper-overview'>Mail: Computer Science Dept., 389 Jane Stanford Way, Stanford, CA 94305</p></li><li><a href='https://crypto.stanford.edu/~dabo/' target='_blank'>My main research focus is applied cryptography and computer security.</a><p class='paper-overview'>My main research focus is applied cryptography and computer security.</p></li><li><a href='https://crypto.stanford.edu/seclab/sem.html' target='_blank'>Computer Security Seminar</a><p class='paper-overview'>Check out our Computer Security Seminar : a bi-weekly seminar open to the public.</p></li></ul></div><div class='person-card'><h4><a href='https://dho.stanford.edu/' target='_blank'>Dan Ho</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='http://visit.stanford.edu/plan/maps.html' target='_blank'>Maps & Directions</a><p class='paper-overview'>Maps & Directions</p></li><li><a href='https://dho.stanford.edu/site/terms/' target='_blank'>Terms of Use</a><p class='paper-overview'>Terms of Use</p></li></ul></div><div class='person-card'><h4><a href='https://web.stanford.edu/~jurafsky/' target='_blank'>Dan Jurafsky</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://arxiv.org/pdf/2506.11035' target='_blank'>Tversky Neural Networks: Psychologically Plausible Deep Learning with Differentiable Tversky Similarity.</a><p class='paper-overview'>Doumbouya, Moussa Koulako Bala, Dan Jurafsky, and Christopher D. Manning.</p></li><li><a href='https://arxiv.org/pdf/2509.21556' target='_blank'>AI for Sustainable Future Foods.</a><p class='paper-overview'>Bianca Datta, Markus J. Buehler, Yvonne Chow, Kristina Gligoric, Dan Jurafsky, David L.</p></li><li><a href='https://arxiv.org/pdf/2505.13995' target='_blank'>ELEPHANT: Measuring and Understanding Social Sycophancy in LLMs.</a><p class='paper-overview'>Myra Cheng*, Sunny Yu*, Cinoo Lee, Pranav Khadpe, Lujain Ibrahim, Dan Jurafsky. ELEPHANT: Measuring and Understanding Social Sycophancy in LLMs.</p></li></ul></div><div class='person-card'><h4><a href='https://neuroailab.stanford.edu' target='_blank'>Daniel Yamins</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://neuroailab.stanford.edu/computational-models-of-sensory-cortex.html' target='_blank'>Computational Models of Sensory Cortex</a><p class='paper-overview'>Computational Models of Sensory Cortex</p></li><li><a href='https://neuroailab.stanford.edu/probing-the-nature-of-visual-representations.html' target='_blank'>Probing the Nature of Visual Representations</a><p class='paper-overview'>Probing the Nature of Visual Representations</p></li></ul></div><div class='person-card'><h4><a href='https://cs.stanford.edu/~diyiy/' target='_blank'>Diyi Yang</a></h4><p class='role'>Member</p><ul class='papers'><li><a href='https://cs.stanford.edu/' target='_blank'>Computer Science Department</a><p class='paper-overview'>Computer Science Department</p></li><li><a href='https://nlp.stanford.edu/' target='_blank'>Natural Language Processing Group</a><p class='paper-overview'>Natural Language Processing Group</p></li><li><a href='https://www.cs.stanford.edu/' target='_blank'>Computer Science Department</a><p class='paper-overview'>I am an assistant professor in the Computer Science Department at Stanford , affiliated with the Stanford NLP Group , Stanford HCI Group , Stanford AI Lab (SAIL) , and Stanford Human-Centered Artificial Intelligence (HAI) . I am interested in Socially Aware NLP , Large Language Models (LLMs) and Human-AI Interaction , with a focus on how LLMs can augment human capabilities across research, work and well-being.</p></li></ul></div></div></section><section class='lab-card'><h2><a href='https://vision.stanford.edu/people.html' target='_blank'>Vision & Learning Lab</a></h2><p class='topics'>Topics: computer vision, multimodal, generative</p><div class='people-grid'></div></section><section class='lab-card'><h2><a href='https://iris.stanford.edu/people' target='_blank'>Stanford IRIS (Robotics)</a></h2><p class='topics'>Topics: robotics, reinforcement learning</p><div class='people-grid'></div></section></body></html>